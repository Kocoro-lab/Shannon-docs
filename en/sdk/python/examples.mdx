---
title: "Code Examples"
description: "Practical examples using the Shannon Python SDK"
---

<Note>
This examples collection is growing. More use cases will be added regularly.
</Note>

## Basic Examples

### Model Selection

```python
from shannon import ShannonClient

client = ShannonClient(base_url="http://localhost:8080")
handle = client.submit_task(
  "Summarize the paragraph into three bullet points focusing on revenue trends. Output: Markdown list.",
  model_tier="small",
  # model_override="gpt-5-nano-2025-08-07",
  # provider_override="openai",
  mode="simple",
)
print(client.wait(handle.task_id).result)
```

### Simple Question Answering

```python
from shannon import ShannonClient

client = ShannonClient(base_url="http://localhost:8080")

# Ask a simple question
handle = client.submit_task(query="What is the capital of France?")
final = client.wait(handle.task_id)
print(f"Answer: {final.result}")
```

### Data Analysis

```python
from shannon import ShannonClient

client = ShannonClient()

# Realistic data analysis
handle = client.submit_task(
    query=(
        "Given the sales data below, calculate:\n"
        "1. Total revenue per product\n"
        "2. Month-over-month growth percentage\n"
        "3. Return top 3 by total revenue\n\n"
        "Data:\n"
        "ProductA: Jan=$10000, Feb=$12000\n"
        "ProductB: Jan=$8000, Feb=$9500\n"
        "ProductC: Jan=$15000, Feb=$14000\n"
        "ProductD: Jan=$5000, Feb=$6000\n\n"
        "Format: JSON array [{product, revenue, mom_growth_pct}]"
    )
)

result = client.wait(handle.task_id)
print(result.result)
```

## Advanced Examples

### Multi-Step Workflow

```python
"""Multi-step workflow example with Shannon SDK"""
from shannon import ShannonClient

def main():
    client = ShannonClient()
    session_id = "quarterly-analysis-demo"

    print("=" * 60)
    print("Multi-Step Workflow Example")
    print("=" * 60)

    # Step 1: Initial data query
    print("\n[Step 1] Loading Q4 data...")
    h1 = client.submit_task(
        query="What is 1000 + 500? This represents Q4 revenue (1000) and expenses (500).",
        session_id=session_id
    )
    result1 = client.wait(h1.task_id)
    print(f"Result: {result1.result}")

    # Step 2: Analysis based on previous context
    print("\n[Step 2] Analyzing trends...")
    h2 = client.submit_task(
        query="Based on the Q4 numbers you just calculated, what is the profit margin percentage?",
        session_id=session_id
    )
    result2 = client.wait(h2.task_id)
    print(f"Result: {result2.result}")

    # Step 3: Summary using all previous context
    print("\n[Step 3] Creating executive summary...")
    h3 = client.submit_task(
        query="Summarize the Q4 financial analysis in 2 sentences.",
        session_id=session_id
    )
    result3 = client.wait(h3.task_id)
    print(f"Result: {result3.result}")

    print("\n" + "=" * 60)
    print("âœ… Multi-step workflow completed!")
    print(f"Session ID: {session_id}")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

### Parallel Processing

```python
"""Parallel processing example with Shannon SDK"""
import asyncio
from shannon import AsyncShannonClient

async def main():
    print("=" * 60)
    print("Parallel Processing Example")
    print("=" * 60)

    async with AsyncShannonClient() as client:
        # Topics to process in parallel
        topics = ["AI", "Quantum Computing", "Biotechnology"]

        print(f"\n[Step 1] Submitting {len(topics)} tasks in parallel...")

        # Submit all tasks concurrently (non-blocking)
        tasks = [
            client.submit_task(
                query=f"Give a one-sentence summary of {topic} and its main application."
            )
            for topic in topics
        ]

        # Wait for all submissions to complete
        handles = await asyncio.gather(*tasks)
        print(f"âœ… All {len(handles)} tasks submitted")

        print("\n[Step 2] Waiting for all results...")

        # Wait for all tasks to complete in parallel
        results = await asyncio.gather(
            *[client.wait(h.task_id) for h in handles]
        )
        print(f"âœ… All {len(results)} tasks completed")

        print("\n[Step 3] Results:")
        print("-" * 60)

        # Display results
        for topic, result in zip(topics, results):
            print(f"\nðŸ“Œ {topic}:")
            print(f"   {result.result}")

            # Safely access metadata if available
            metadata = []
            if hasattr(result, 'metadata') and result.metadata:
                model = result.metadata.get('model_used') or result.metadata.get('model')
                if model:
                    metadata.append(f"Model: {model}")
                tokens = result.metadata.get('total_tokens')
                if tokens:
                    metadata.append(f"Tokens: {tokens}")

            if metadata:
                print(f"   ({', '.join(metadata)})")

        print("\n" + "=" * 60)
        print("âœ… Parallel processing completed!")
        print(f"Processed {len(topics)} topics concurrently")
        print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
```

### Streaming with filters

```python
"""Streaming with event filters example"""
from shannon import ShannonClient, EventType

def main():
    print("=" * 60)
    print("Streaming with Filters Example")
    print("=" * 60)

    client = ShannonClient()

    print("\n[Step 1] Submitting task...")
    handle = client.submit_task(
        query=(
            "Compare AWS, Azure, and GCP pricing models in 3 sentences. "
            "Stream the output as you generate it."
        )
    )
    print(f"âœ… Task submitted: {handle.task_id}")

    print("\n[Step 2] Streaming with filters [LLM_OUTPUT, WORKFLOW_COMPLETED]...")
    print("-" * 60)

    event_count = 0
    llm_outputs = []

    # Stream only LLM_OUTPUT and WORKFLOW_COMPLETED events
    for event in client.stream(
        handle.workflow_id,
        types=[EventType.LLM_OUTPUT, EventType.WORKFLOW_COMPLETED]
    ):
        event_count += 1
        print(f"[{event_count}] {event.type}")

        if event.type == EventType.LLM_OUTPUT:
            print(f"    Content: {event.message[:80]}...")
            llm_outputs.append(event.message)

        if event.type == EventType.WORKFLOW_COMPLETED:
            print(f"    Status: {event.message}")
            break

    print("\n" + "-" * 60)
    print(f"âœ… Received {event_count} filtered events")
    print(f"âœ… Captured {len(llm_outputs)} LLM outputs")

    print("\n[Step 3] Full result:")
    print("-" * 60)
    final = client.wait(handle.task_id)
    print(final.result)

    print("\n" + "=" * 60)
    print("âœ… Streaming with filters completed!")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

See the full list of event types in the [Event Types Catalog](/en/api/event-types).

## Real-World Use Cases

{/* Removed outdated customer support bot example (used unsupported session APIs). */}

### Code Review Assistant

```python
def automated_code_review(file_path, language="python"):
    client = ShannonClient()

    with open(file_path, 'r') as f:
        code = f.read()

    handle = client.submit_task(
        query=f"Review this {language} code for bugs, security issues, and improvements",
        # Mode auto-selected,
        context={"code": code}
    )

    # Track progress (generic)
    for event in client.stream(handle.workflow_id):
        print(f"[{event.type}] {event.message}")
        if event.type == "WORKFLOW_COMPLETED":
            break

    return client.wait(handle.task_id)

# Use it
review = automated_code_review("app.py")
print(review)
```

{/* Removed verbose research assistant example for brevity. */}

## Error Handling Examples

```python
from shannon import ShannonClient, ShannonError, ConnectionError, TaskTimeoutError
import time

def robust_task_submission(query, max_retries=3):
    client = ShannonClient()

    for attempt in range(max_retries):
        try:
            # Submit task
            handle = client.submit_task(query=query)  # Mode auto-selected

            # Wait with timeout
            result = client.wait(handle.task_id, timeout=300)

            return result

        except ConnectionError:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # Exponential backoff
                continue
            raise

        except TaskTimeoutError:
            print("Task timed out")
            raise
        except ShannonError as e:
            print(f"Shannon error: {e}")
            raise
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Async Usage" icon="bolt" href="/en/sdk/python/async-usage">
    Async/await patterns
  </Card>
  <Card title="Error Handling" icon="shield" href="/en/sdk/python/error-handling">
    Handle errors properly
  </Card>
</CardGroup>
